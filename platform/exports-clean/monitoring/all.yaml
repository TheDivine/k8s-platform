apiVersion: v1
items:
  - apiVersion: v1
    kind: Pod
    metadata:
      annotations:
        cni.projectcalico.org/containerID: 89e34170ad099cdefae60516184fe46b3a95da1ab10909bf192b9a11e9ab9b32
        cni.projectcalico.org/podIP: 10.244.101.176/32
        cni.projectcalico.org/podIPs: 10.244.101.176/32
        kubectl.kubernetes.io/default-container: alertmanager
      generateName: alertmanager-monitoring-kube-prometheus-alertmanager-
      labels:
        alertmanager: monitoring-kube-prometheus-alertmanager
        app.kubernetes.io/instance: monitoring-kube-prometheus-alertmanager
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: alertmanager
        app.kubernetes.io/version: 0.29.0
        apps.kubernetes.io/pod-index: "0"
        controller-revision-hash: alertmanager-monitoring-kube-prometheus-alertmanager-5ff8c475cd
        statefulset.kubernetes.io/pod-name: alertmanager-monitoring-kube-prometheus-alertmanager-0
      name: alertmanager-monitoring-kube-prometheus-alertmanager-0
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: StatefulSet
          name: alertmanager-monitoring-kube-prometheus-alertmanager
          uid: a2b029f1-cf2d-4baf-880a-2d97e1344793
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app.kubernetes.io/name
                      operator: In
                      values:
                        - alertmanager
                    - key: alertmanager
                      operator: In
                      values:
                        - monitoring-kube-prometheus-alertmanager
                topologyKey: kubernetes.io/hostname
              weight: 100
      automountServiceAccountToken: true
      containers:
        - args:
            - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
            - --storage.path=/alertmanager
            - --data.retention=120h
            - --cluster.listen-address=
            - --web.listen-address=:9093
            - --web.external-url=http://monitoring-kube-prometheus-alertmanager.monitoring:9093
            - --web.route-prefix=/
            - --cluster.label=monitoring/monitoring-kube-prometheus-alertmanager
            - --cluster.peer=alertmanager-monitoring-kube-prometheus-alertmanager-0.alertmanager-operated:9094
            - --cluster.reconnect-timeout=5m
            - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
          image: quay.io/prometheus/alertmanager:v0.29.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /-/healthy
              port: http-web
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 3
          name: alertmanager
          ports:
            - containerPort: 9093
              name: http-web
              protocol: TCP
            - containerPort: 9094
              name: mesh-tcp
              protocol: TCP
            - containerPort: 9094
              name: mesh-udp
              protocol: UDP
          readinessProbe:
            failureThreshold: 10
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            initialDelaySeconds: 3
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources:
            requests:
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
            - mountPath: /etc/alertmanager/config
              name: config-volume
            - mountPath: /etc/alertmanager/config_out
              name: config-out
              readOnly: true
            - mountPath: /etc/alertmanager/certs
              name: tls-assets
              readOnly: true
            - mountPath: /alertmanager
              name: alertmanager-monitoring-kube-prometheus-alertmanager-db
            - mountPath: /etc/alertmanager/web_config/web-config.yaml
              name: web-config
              readOnly: true
              subPath: web-config.yaml
            - mountPath: /etc/alertmanager/cluster_tls_config/cluster-tls-config.yaml
              name: cluster-tls-config
              readOnly: true
              subPath: cluster-tls-config.yaml
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-w9fm5
              readOnly: true
        - args:
            - --listen-address=:8080
            - --web-config-file=/etc/alertmanager/web_config/web-config.yaml
            - --reload-url=http://127.0.0.1:9093/-/reload
            - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
            - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
            - --watched-dir=/etc/alertmanager/config
          command:
            - /bin/prometheus-config-reloader
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: SHARD
              value: "-1"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
          imagePullPolicy: IfNotPresent
          name: config-reloader
          ports:
            - containerPort: 8080
              name: reloader-web
              protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
            - mountPath: /etc/alertmanager/config
              name: config-volume
              readOnly: true
            - mountPath: /etc/alertmanager/config_out
              name: config-out
            - mountPath: /etc/alertmanager/web_config/web-config.yaml
              name: web-config
              readOnly: true
              subPath: web-config.yaml
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-w9fm5
              readOnly: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      hostname: alertmanager-monitoring-kube-prometheus-alertmanager-0
      initContainers:
        - args:
            - --watch-interval=0
            - --listen-address=:8081
            - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
            - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
            - --watched-dir=/etc/alertmanager/config
          command:
            - /bin/prometheus-config-reloader
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: SHARD
              value: "-1"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
          imagePullPolicy: IfNotPresent
          name: init-config-reloader
          ports:
            - containerPort: 8081
              name: reloader-init
              protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
            - mountPath: /etc/alertmanager/config
              name: config-volume
              readOnly: true
            - mountPath: /etc/alertmanager/config_out
              name: config-out
            - mountPath: /etc/alertmanager/web_config/web-config.yaml
              name: web-config
              readOnly: true
              subPath: web-config.yaml
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-w9fm5
              readOnly: true
      nodeName: s231226.wholesaleinternet.net
      preemptionPolicy: PreemptLowerPriority
      priority: 0
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 2000
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      serviceAccount: monitoring-kube-prometheus-alertmanager
      serviceAccountName: monitoring-kube-prometheus-alertmanager
      subdomain: alertmanager-operated
      terminationGracePeriodSeconds: 120
      tolerations:
        - effect: NoExecute
          key: node.kubernetes.io/not-ready
          operator: Exists
          tolerationSeconds: 300
        - effect: NoExecute
          key: node.kubernetes.io/unreachable
          operator: Exists
          tolerationSeconds: 300
      volumes:
        - name: config-volume
          secret:
            defaultMode: 420
            secretName: alertmanager-monitoring-kube-prometheus-alertmanager-generated
        - name: tls-assets
          projected:
            defaultMode: 420
            sources:
              - secret:
                  name: alertmanager-monitoring-kube-prometheus-alertmanager-tls-assets-0
        - emptyDir:
            medium: Memory
          name: config-out
        - name: web-config
          secret:
            defaultMode: 420
            secretName: alertmanager-monitoring-kube-prometheus-alertmanager-web-config
        - name: cluster-tls-config
          secret:
            defaultMode: 420
            secretName: alertmanager-monitoring-kube-prometheus-alertmanager-cluster-tls-config
        - emptyDir: {}
          name: alertmanager-monitoring-kube-prometheus-alertmanager-db
        - name: kube-api-access-w9fm5
          projected:
            defaultMode: 420
            sources:
              - serviceAccountToken:
                  expirationSeconds: 3607
                  path: token
              - configMap:
                  items:
                    - key: ca.crt
                      path: ca.crt
                  name: kube-root-ca.crt
              - downwardAPI:
                  items:
                    - fieldRef:
                        apiVersion: v1
                        fieldPath: metadata.namespace
                      path: namespace
  - apiVersion: v1
    kind: Pod
    metadata:
      annotations:
        checksum/config: b19ad569963f94db78b150b97c208a759fb48b7234cd8be344c5218229c5c6c8
        checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
        checksum/secret: 7f0cdf9c1d7c2511f85367d925e7b20f3e81cbfaabc23fd10f289b0f52eedd76
        cni.projectcalico.org/containerID: e21dbeffaa36d07b3b1891d1359676fd10cc88a3e1f309e9a28637983892e70d
        cni.projectcalico.org/podIP: 10.244.101.180/32
        cni.projectcalico.org/podIPs: 10.244.101.180/32
        kubectl.kubernetes.io/default-container: grafana
      generateName: monitoring-grafana-7466f5b78c-
      labels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
        app.kubernetes.io/version: 12.3.0
        helm.sh/chart: grafana-10.1.5
        pod-template-hash: 7466f5b78c
      name: monitoring-grafana-7466f5b78c-qtbqq
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: ReplicaSet
          name: monitoring-grafana-7466f5b78c
          uid: 9c046646-5e40-4087-92b2-47d90096f427
    spec:
      automountServiceAccountToken: true
      containers:
        - env:
            - name: METHOD
              value: WATCH
            - name: LABEL
              value: grafana_dashboard
            - name: LABEL_VALUE
              value: "1"
            - name: FOLDER
              value: /tmp/dashboards
            - name: RESOURCE
              value: both
            - name: NAMESPACE
              value: ALL
            - name: REQ_USERNAME
              valueFrom:
                secretKeyRef:
                  key: admin-user
                  name: monitoring-grafana
            - name: REQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: admin-password
                  name: monitoring-grafana
            - name: REQ_URL
              value: http://localhost:3000/api/admin/provisioning/dashboards/reload
            - name: REQ_METHOD
              value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.30.10
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /tmp/dashboards
              name: sc-dashboard-volume
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-p8zpd
              readOnly: true
        - env:
            - name: METHOD
              value: WATCH
            - name: LABEL
              value: grafana_datasource
            - name: LABEL_VALUE
              value: "1"
            - name: FOLDER
              value: /etc/grafana/provisioning/datasources
            - name: RESOURCE
              value: both
            - name: REQ_USERNAME
              valueFrom:
                secretKeyRef:
                  key: admin-user
                  name: monitoring-grafana
            - name: REQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: admin-password
                  name: monitoring-grafana
            - name: REQ_URL
              value: http://localhost:3000/api/admin/provisioning/datasources/reload
            - name: REQ_METHOD
              value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.30.10
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /etc/grafana/provisioning/datasources
              name: sc-datasources-volume
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-p8zpd
              readOnly: true
        - env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: GF_SECURITY_ADMIN_USER
              valueFrom:
                secretKeyRef:
                  key: admin-user
                  name: monitoring-grafana
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: admin-password
                  name: monitoring-grafana
            - name: GF_PATHS_DATA
              value: /var/lib/grafana/
            - name: GF_PATHS_LOGS
              value: /var/log/grafana
            - name: GF_PATHS_PLUGINS
              value: /var/lib/grafana/plugins
            - name: GF_PATHS_PROVISIONING
              value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:12.3.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
            - containerPort: 3000
              name: grafana
              protocol: TCP
            - containerPort: 9094
              name: gossip-tcp
              protocol: TCP
            - containerPort: 9094
              name: gossip-udp
              protocol: UDP
            - containerPort: 6060
              name: profiling
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /etc/grafana/grafana.ini
              name: config
              subPath: grafana.ini
            - mountPath: /var/lib/grafana
              name: storage
            - mountPath: /tmp/dashboards
              name: sc-dashboard-volume
            - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
              name: sc-dashboard-provider
              subPath: provider.yaml
            - mountPath: /etc/grafana/provisioning/datasources
              name: sc-datasources-volume
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-p8zpd
              readOnly: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      initContainers:
        - command:
            - chown
            - -R
            - 472:472
            - /var/lib/grafana
          image: docker.io/library/busybox:1.31.1
          imagePullPolicy: IfNotPresent
          name: init-chown-data
          resources: {}
          securityContext:
            capabilities:
              add:
                - CHOWN
              drop:
                - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /var/lib/grafana
              name: storage
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-p8zpd
              readOnly: true
      nodeName: s231226.wholesaleinternet.net
      preemptionPolicy: PreemptLowerPriority
      priority: 0
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsNonRoot: true
        runAsUser: 472
      serviceAccount: monitoring-grafana
      serviceAccountName: monitoring-grafana
      shareProcessNamespace: false
      terminationGracePeriodSeconds: 30
      tolerations:
        - effect: NoExecute
          key: node.kubernetes.io/not-ready
          operator: Exists
          tolerationSeconds: 300
        - effect: NoExecute
          key: node.kubernetes.io/unreachable
          operator: Exists
          tolerationSeconds: 300
      volumes:
        - configMap:
            defaultMode: 420
            name: monitoring-grafana
          name: config
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: monitoring-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
        - name: kube-api-access-p8zpd
          projected:
            defaultMode: 420
            sources:
              - serviceAccountToken:
                  expirationSeconds: 3607
                  path: token
              - configMap:
                  items:
                    - key: ca.crt
                      path: ca.crt
                  name: kube-root-ca.crt
              - downwardAPI:
                  items:
                    - fieldRef:
                        apiVersion: v1
                        fieldPath: metadata.namespace
                      path: namespace
  - apiVersion: v1
    kind: Pod
    metadata:
      annotations:
        cni.projectcalico.org/containerID: aeb7c2c09f70b7cdc82a35db421bbe5753db29ebc900d41f1ded40c4b23d78ce
        cni.projectcalico.org/podIP: 10.244.101.174/32
        cni.projectcalico.org/podIPs: 10.244.101.174/32
      generateName: monitoring-kube-prometheus-operator-568b8d6b68-
      labels:
        app: kube-prometheus-stack-operator
        app.kubernetes.io/component: prometheus-operator
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
        app.kubernetes.io/part-of: kube-prometheus-stack
        app.kubernetes.io/version: 79.6.1
        chart: kube-prometheus-stack-79.6.1
        heritage: Helm
        pod-template-hash: 568b8d6b68
        release: monitoring
      name: monitoring-kube-prometheus-operator-568b8d6b68-vsw28
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: ReplicaSet
          name: monitoring-kube-prometheus-operator-568b8d6b68
          uid: 4f7128b4-f1dd-4854-8fb3-2782817f0058
    spec:
      automountServiceAccountToken: true
      containers:
        - args:
            - --kubelet-service=kube-system/monitoring-kube-prometheus-kubelet
            - --kubelet-endpoints=true
            - --kubelet-endpointslice=false
            - --localhost=127.0.0.1
            - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
            - --config-reloader-cpu-request=0
            - --config-reloader-cpu-limit=0
            - --config-reloader-memory-request=0
            - --config-reloader-memory-limit=0
            - --thanos-default-base-image=quay.io/thanos/thanos:v0.40.1
            - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
            - --web.enable-tls=true
            - --web.cert-file=/cert/cert
            - --web.key-file=/cert/key
            - --web.listen-address=:10250
            - --web.tls-min-version=VersionTLS13
          env:
            - name: GOGC
              value: "30"
          image: quay.io/prometheus-operator/prometheus-operator:v0.86.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: kube-prometheus-stack
          ports:
            - containerPort: 10250
              name: https
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /cert
              name: tls-secret
              readOnly: true
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-mxscm
              readOnly: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      nodeName: s231226.wholesaleinternet.net
      preemptionPolicy: PreemptLowerPriority
      priority: 0
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      serviceAccount: monitoring-kube-prometheus-operator
      serviceAccountName: monitoring-kube-prometheus-operator
      terminationGracePeriodSeconds: 30
      tolerations:
        - effect: NoExecute
          key: node.kubernetes.io/not-ready
          operator: Exists
          tolerationSeconds: 300
        - effect: NoExecute
          key: node.kubernetes.io/unreachable
          operator: Exists
          tolerationSeconds: 300
      volumes:
        - name: tls-secret
          secret:
            defaultMode: 420
            secretName: monitoring-kube-prometheus-admission
        - name: kube-api-access-mxscm
          projected:
            defaultMode: 420
            sources:
              - serviceAccountToken:
                  expirationSeconds: 3607
                  path: token
              - configMap:
                  items:
                    - key: ca.crt
                      path: ca.crt
                  name: kube-root-ca.crt
              - downwardAPI:
                  items:
                    - fieldRef:
                        apiVersion: v1
                        fieldPath: metadata.namespace
                      path: namespace
  - apiVersion: v1
    kind: Pod
    metadata:
      annotations:
        cni.projectcalico.org/containerID: a6946a7c2aa7a2949dd3b94a9085653bc0f1d62b209cddc30b14cf946c6a38b7
        cni.projectcalico.org/podIP: 10.244.101.173/32
        cni.projectcalico.org/podIPs: 10.244.101.173/32
      generateName: monitoring-kube-state-metrics-7984768b56-
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/part-of: kube-state-metrics
        app.kubernetes.io/version: 2.17.0
        helm.sh/chart: kube-state-metrics-6.4.1
        pod-template-hash: 7984768b56
        release: monitoring
      name: monitoring-kube-state-metrics-7984768b56-mxbdp
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: ReplicaSet
          name: monitoring-kube-state-metrics-7984768b56
          uid: c5c28faf-5553-48a8-8ef5-b57dfb71b619
    spec:
      automountServiceAccountToken: true
      containers:
        - args:
            - --port=8080
            - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
            - containerPort: 8080
              name: http
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8081
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-f5q5r
              readOnly: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      nodeName: s231226.wholesaleinternet.net
      preemptionPolicy: PreemptLowerPriority
      priority: 0
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      serviceAccount: monitoring-kube-state-metrics
      serviceAccountName: monitoring-kube-state-metrics
      terminationGracePeriodSeconds: 30
      tolerations:
        - effect: NoExecute
          key: node.kubernetes.io/not-ready
          operator: Exists
          tolerationSeconds: 300
        - effect: NoExecute
          key: node.kubernetes.io/unreachable
          operator: Exists
          tolerationSeconds: 300
      volumes:
        - name: kube-api-access-f5q5r
          projected:
            defaultMode: 420
            sources:
              - serviceAccountToken:
                  expirationSeconds: 3607
                  path: token
              - configMap:
                  items:
                    - key: ca.crt
                      path: ca.crt
                  name: kube-root-ca.crt
              - downwardAPI:
                  items:
                    - fieldRef:
                        apiVersion: v1
                        fieldPath: metadata.namespace
                      path: namespace
  - apiVersion: v1
    kind: Pod
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      generateName: monitoring-prometheus-node-exporter-
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: prometheus-node-exporter
        app.kubernetes.io/part-of: prometheus-node-exporter
        app.kubernetes.io/version: 1.10.2
        controller-revision-hash: 777b747b7c
        helm.sh/chart: prometheus-node-exporter-4.49.1
        jobLabel: node-exporter
        pod-template-generation: "1"
        release: monitoring
      name: monitoring-prometheus-node-exporter-7b8vn
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: DaemonSet
          name: monitoring-prometheus-node-exporter
          uid: 8e8a9bb5-81f8-432f-b751-4783e2918249
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchFields:
                  - key: metadata.name
                    operator: In
                    values:
                      - s231226.wholesaleinternet.net
      automountServiceAccountToken: false
      containers:
        - args:
            - --path.procfs=/host/proc
            - --path.sysfs=/host/sys
            - --path.rootfs=/host/root
            - --path.udev.data=/host/root/run/udev/data
            - --web.listen-address=[$(HOST_IP)]:9100
            - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/containerd/.+|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
            - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs|erofs)$
          env:
            - name: HOST_IP
              value: 0.0.0.0
          image: quay.io/prometheus/node-exporter:v1.10.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http-metrics
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: node-exporter
          ports:
            - containerPort: 9100
              hostPort: 9100
              name: http-metrics
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http-metrics
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /host/proc
              name: proc
              readOnly: true
            - mountPath: /host/sys
              name: sys
              readOnly: true
            - mountPath: /host/root
              mountPropagation: HostToContainer
              name: root
              readOnly: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      hostNetwork: true
      hostPID: true
      nodeName: s231226.wholesaleinternet.net
      nodeSelector:
        kubernetes.io/os: linux
      preemptionPolicy: PreemptLowerPriority
      priority: 0
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccount: monitoring-prometheus-node-exporter
      serviceAccountName: monitoring-prometheus-node-exporter
      terminationGracePeriodSeconds: 30
      tolerations:
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          key: node.kubernetes.io/not-ready
          operator: Exists
        - effect: NoExecute
          key: node.kubernetes.io/unreachable
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/disk-pressure
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/memory-pressure
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/pid-pressure
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/unschedulable
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/network-unavailable
          operator: Exists
      volumes:
        - hostPath:
            path: /proc
            type: ""
          name: proc
        - hostPath:
            path: /sys
            type: ""
          name: sys
        - hostPath:
            path: /
            type: ""
          name: root
  - apiVersion: v1
    kind: Pod
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      generateName: monitoring-prometheus-node-exporter-
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: prometheus-node-exporter
        app.kubernetes.io/part-of: prometheus-node-exporter
        app.kubernetes.io/version: 1.10.2
        controller-revision-hash: 777b747b7c
        helm.sh/chart: prometheus-node-exporter-4.49.1
        jobLabel: node-exporter
        pod-template-generation: "1"
        release: monitoring
      name: monitoring-prometheus-node-exporter-v4kp6
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: DaemonSet
          name: monitoring-prometheus-node-exporter
          uid: 8e8a9bb5-81f8-432f-b751-4783e2918249
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchFields:
                  - key: metadata.name
                    operator: In
                    values:
                      - hcp.kwiki.it.com
      automountServiceAccountToken: false
      containers:
        - args:
            - --path.procfs=/host/proc
            - --path.sysfs=/host/sys
            - --path.rootfs=/host/root
            - --path.udev.data=/host/root/run/udev/data
            - --web.listen-address=[$(HOST_IP)]:9100
            - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/containerd/.+|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
            - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs|erofs)$
          env:
            - name: HOST_IP
              value: 0.0.0.0
          image: quay.io/prometheus/node-exporter:v1.10.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http-metrics
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: node-exporter
          ports:
            - containerPort: 9100
              hostPort: 9100
              name: http-metrics
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http-metrics
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
            - mountPath: /host/proc
              name: proc
              readOnly: true
            - mountPath: /host/sys
              name: sys
              readOnly: true
            - mountPath: /host/root
              mountPropagation: HostToContainer
              name: root
              readOnly: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      hostNetwork: true
      hostPID: true
      nodeName: hcp.kwiki.it.com
      nodeSelector:
        kubernetes.io/os: linux
      preemptionPolicy: PreemptLowerPriority
      priority: 0
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccount: monitoring-prometheus-node-exporter
      serviceAccountName: monitoring-prometheus-node-exporter
      terminationGracePeriodSeconds: 30
      tolerations:
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          key: node.kubernetes.io/not-ready
          operator: Exists
        - effect: NoExecute
          key: node.kubernetes.io/unreachable
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/disk-pressure
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/memory-pressure
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/pid-pressure
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/unschedulable
          operator: Exists
        - effect: NoSchedule
          key: node.kubernetes.io/network-unavailable
          operator: Exists
      volumes:
        - hostPath:
            path: /proc
            type: ""
          name: proc
        - hostPath:
            path: /sys
            type: ""
          name: sys
        - hostPath:
            path: /
            type: ""
          name: root
  - apiVersion: v1
    kind: Pod
    metadata:
      annotations:
        cni.projectcalico.org/containerID: aebe857b375b5cfb9bf9ee56c581b492643e6085589285e9ed2df92a7441416a
        cni.projectcalico.org/podIP: 10.244.101.178/32
        cni.projectcalico.org/podIPs: 10.244.101.178/32
        kubectl.kubernetes.io/default-container: prometheus
      generateName: prometheus-monitoring-kube-prometheus-prometheus-
      labels:
        app.kubernetes.io/instance: monitoring-kube-prometheus-prometheus
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/version: 3.7.3
        apps.kubernetes.io/pod-index: "0"
        controller-revision-hash: prometheus-monitoring-kube-prometheus-prometheus-556975765c
        operator.prometheus.io/name: monitoring-kube-prometheus-prometheus
        operator.prometheus.io/shard: "0"
        prometheus: monitoring-kube-prometheus-prometheus
        statefulset.kubernetes.io/pod-name: prometheus-monitoring-kube-prometheus-prometheus-0
      name: prometheus-monitoring-kube-prometheus-prometheus-0
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: StatefulSet
          name: prometheus-monitoring-kube-prometheus-prometheus
          uid: b542103e-3b25-450a-b904-c80da981e17c
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app.kubernetes.io/name
                      operator: In
                      values:
                        - prometheus
                    - key: app.kubernetes.io/instance
                      operator: In
                      values:
                        - monitoring-kube-prometheus-prometheus
                topologyKey: kubernetes.io/hostname
              weight: 100
      automountServiceAccountToken: true
      containers:
        - args:
            - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
            - --web.enable-lifecycle
            - --web.external-url=http://prometheus.kwiki.it.com/
            - --web.route-prefix=/
            - --storage.tsdb.retention.time=10d
            - --storage.tsdb.path=/prometheus
            - --storage.tsdb.wal-compression
            - --web.config.file=/etc/prometheus/web_config/web-config.yaml
          image: quay.io/prometheus/prometheus:v3.7.3
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 6
            httpGet:
              path: /-/healthy
              port: http-web
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          name: prometheus
          ports:
            - containerPort: 9090
              name: http-web
              protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: true
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /-/ready
              port: http-web
              scheme: HTTP
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 3
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
            - mountPath: /etc/prometheus/config_out
              name: config-out
              readOnly: true
            - mountPath: /etc/prometheus/certs
              name: tls-assets
              readOnly: true
            - mountPath: /prometheus
              name: prometheus-monitoring-kube-prometheus-prometheus-db
              subPath: prometheus-db
            - mountPath: /etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
              name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
            - mountPath: /etc/prometheus/web_config/web-config.yaml
              name: web-config
              readOnly: true
              subPath: web-config.yaml
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-czgv7
              readOnly: true
        - args:
            - --listen-address=:8080
            - --reload-url=http://127.0.0.1:9090/-/reload
            - --config-file=/etc/prometheus/config/prometheus.yaml.gz
            - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
            - --watched-dir=/etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
          command:
            - /bin/prometheus-config-reloader
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: SHARD
              value: "0"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
          imagePullPolicy: IfNotPresent
          name: config-reloader
          ports:
            - containerPort: 8080
              name: reloader-web
              protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
            - mountPath: /etc/prometheus/config
              name: config
            - mountPath: /etc/prometheus/config_out
              name: config-out
            - mountPath: /etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
              name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-czgv7
              readOnly: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      hostname: prometheus-monitoring-kube-prometheus-prometheus-0
      initContainers:
        - args:
            - --watch-interval=0
            - --listen-address=:8081
            - --config-file=/etc/prometheus/config/prometheus.yaml.gz
            - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
            - --watched-dir=/etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
          command:
            - /bin/prometheus-config-reloader
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: SHARD
              value: "0"
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
          imagePullPolicy: IfNotPresent
          name: init-config-reloader
          ports:
            - containerPort: 8081
              name: reloader-init
              protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
                - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: FallbackToLogsOnError
          volumeMounts:
            - mountPath: /etc/prometheus/config
              name: config
            - mountPath: /etc/prometheus/config_out
              name: config-out
            - mountPath: /etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
              name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
            - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
              name: kube-api-access-czgv7
              readOnly: true
      nodeName: s231226.wholesaleinternet.net
      preemptionPolicy: PreemptLowerPriority
      priority: 0
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        fsGroup: 2000
        runAsGroup: 2000
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      serviceAccount: monitoring-kube-prometheus-prometheus
      serviceAccountName: monitoring-kube-prometheus-prometheus
      shareProcessNamespace: false
      subdomain: prometheus-operated
      terminationGracePeriodSeconds: 600
      tolerations:
        - effect: NoExecute
          key: node.kubernetes.io/not-ready
          operator: Exists
          tolerationSeconds: 300
        - effect: NoExecute
          key: node.kubernetes.io/unreachable
          operator: Exists
          tolerationSeconds: 300
      volumes:
        - name: prometheus-monitoring-kube-prometheus-prometheus-db
          persistentVolumeClaim:
            claimName: prometheus-monitoring-kube-prometheus-prometheus-db-prometheus-monitoring-kube-prometheus-prometheus-0
        - name: config
          secret:
            defaultMode: 420
            secretName: prometheus-monitoring-kube-prometheus-prometheus
        - name: tls-assets
          projected:
            defaultMode: 420
            sources:
              - secret:
                  name: prometheus-monitoring-kube-prometheus-prometheus-tls-assets-0
        - emptyDir:
            medium: Memory
          name: config-out
        - configMap:
            defaultMode: 420
            name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
          name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
        - name: web-config
          secret:
            defaultMode: 420
            secretName: prometheus-monitoring-kube-prometheus-prometheus-web-config
        - name: kube-api-access-czgv7
          projected:
            defaultMode: 420
            sources:
              - serviceAccountToken:
                  expirationSeconds: 3607
                  path: token
              - configMap:
                  items:
                    - key: ca.crt
                      path: ca.crt
                  name: kube-root-ca.crt
              - downwardAPI:
                  items:
                    - fieldRef:
                        apiVersion: v1
                        fieldPath: metadata.namespace
                      path: namespace
  - apiVersion: v1
    kind: Service
    metadata:
      labels:
        app.kubernetes.io/managed-by: prometheus-operator
        managed-by: prometheus-operator
        operated-alertmanager: "true"
      name: alertmanager-operated
      namespace: monitoring
      ownerReferences:
        - apiVersion: monitoring.coreos.com/v1
          kind: Alertmanager
          name: monitoring-kube-prometheus-alertmanager
          uid: 56e0a879-e38a-4b61-88ef-52a0181a7209
    spec:
      clusterIP: None
      clusterIPs:
        - None
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: http-web
          port: 9093
          protocol: TCP
          targetPort: http-web
        - name: tcp-mesh
          port: 9094
          protocol: TCP
          targetPort: mesh-tcp
        - name: udp-mesh
          port: 9094
          protocol: UDP
          targetPort: mesh-udp
      publishNotReadyAddresses: true
      selector:
        app.kubernetes.io/name: alertmanager
      sessionAffinity: None
      type: ClusterIP
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: grafana
        app.kubernetes.io/version: 12.3.0
        helm.sh/chart: grafana-10.1.5
      name: monitoring-grafana
      namespace: monitoring
    spec:
      clusterIP: 10.104.12.66
      clusterIPs:
        - 10.104.12.66
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: http-web
          port: 80
          protocol: TCP
          targetPort: grafana
      selector:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
      sessionAffinity: None
      type: ClusterIP
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app: kube-prometheus-stack-alertmanager
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: kube-prometheus-stack
        app.kubernetes.io/version: 79.6.1
        chart: kube-prometheus-stack-79.6.1
        heritage: Helm
        release: monitoring
        self-monitor: "true"
      name: monitoring-kube-prometheus-alertmanager
      namespace: monitoring
    spec:
      clusterIP: 10.103.15.108
      clusterIPs:
        - 10.103.15.108
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: http-web
          port: 9093
          protocol: TCP
          targetPort: 9093
        - appProtocol: http
          name: reloader-web
          port: 8080
          protocol: TCP
          targetPort: reloader-web
      selector:
        alertmanager: monitoring-kube-prometheus-alertmanager
        app.kubernetes.io/name: alertmanager
      sessionAffinity: None
      type: ClusterIP
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app: kube-prometheus-stack-operator
        app.kubernetes.io/component: prometheus-operator
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
        app.kubernetes.io/part-of: kube-prometheus-stack
        app.kubernetes.io/version: 79.6.1
        chart: kube-prometheus-stack-79.6.1
        heritage: Helm
        release: monitoring
      name: monitoring-kube-prometheus-operator
      namespace: monitoring
    spec:
      clusterIP: 10.108.145.35
      clusterIPs:
        - 10.108.145.35
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: https
          port: 443
          protocol: TCP
          targetPort: https
      selector:
        app: kube-prometheus-stack-operator
        release: monitoring
      sessionAffinity: None
      type: ClusterIP
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app: kube-prometheus-stack-prometheus
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: kube-prometheus-stack
        app.kubernetes.io/version: 79.6.1
        chart: kube-prometheus-stack-79.6.1
        heritage: Helm
        release: monitoring
        self-monitor: "true"
      name: monitoring-kube-prometheus-prometheus
      namespace: monitoring
    spec:
      clusterIP: 10.97.69.182
      clusterIPs:
        - 10.97.69.182
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: http-web
          port: 9090
          protocol: TCP
          targetPort: 9090
        - appProtocol: http
          name: reloader-web
          port: 8080
          protocol: TCP
          targetPort: reloader-web
      selector:
        app.kubernetes.io/name: prometheus
        operator.prometheus.io/name: monitoring-kube-prometheus-prometheus
      sessionAffinity: None
      type: ClusterIP
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/part-of: kube-state-metrics
        app.kubernetes.io/version: 2.17.0
        helm.sh/chart: kube-state-metrics-6.4.1
        release: monitoring
      name: monitoring-kube-state-metrics
      namespace: monitoring
    spec:
      clusterIP: 10.109.34.76
      clusterIPs:
        - 10.109.34.76
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: http
          port: 8080
          protocol: TCP
          targetPort: http
      selector:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: kube-state-metrics
      sessionAffinity: None
      type: ClusterIP
  - apiVersion: v1
    kind: Service
    metadata:
      annotations:
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
        prometheus.io/scrape: "true"
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: prometheus-node-exporter
        app.kubernetes.io/part-of: prometheus-node-exporter
        app.kubernetes.io/version: 1.10.2
        helm.sh/chart: prometheus-node-exporter-4.49.1
        jobLabel: node-exporter
        release: monitoring
      name: monitoring-prometheus-node-exporter
      namespace: monitoring
    spec:
      clusterIP: 10.107.63.237
      clusterIPs:
        - 10.107.63.237
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: http-metrics
          port: 9100
          protocol: TCP
          targetPort: 9100
      selector:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: prometheus-node-exporter
      sessionAffinity: None
      type: ClusterIP
  - apiVersion: v1
    kind: Service
    metadata:
      labels:
        app.kubernetes.io/managed-by: prometheus-operator
        managed-by: prometheus-operator
        operated-prometheus: "true"
      name: prometheus-operated
      namespace: monitoring
      ownerReferences:
        - apiVersion: monitoring.coreos.com/v1
          kind: Prometheus
          name: monitoring-kube-prometheus-prometheus
          uid: d52be81e-22a1-483b-861a-2ca76ba85f38
    spec:
      clusterIP: None
      clusterIPs:
        - None
      internalTrafficPolicy: Cluster
      ipFamilies:
        - IPv4
      ipFamilyPolicy: SingleStack
      ports:
        - name: http-web
          port: 9090
          protocol: TCP
          targetPort: http-web
      selector:
        app.kubernetes.io/name: prometheus
      sessionAffinity: None
      type: ClusterIP
  - apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      annotations:
        deprecated.daemonset.template.generation: "1"
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: prometheus-node-exporter
        app.kubernetes.io/part-of: prometheus-node-exporter
        app.kubernetes.io/version: 1.10.2
        helm.sh/chart: prometheus-node-exporter-4.49.1
        release: monitoring
      name: monitoring-prometheus-node-exporter
      namespace: monitoring
    spec:
      revisionHistoryLimit: 10
      selector:
        matchLabels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: prometheus-node-exporter
      template:
        metadata:
          annotations:
            cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
          creationTimestamp: null
          labels:
            app.kubernetes.io/component: metrics
            app.kubernetes.io/instance: monitoring
            app.kubernetes.io/managed-by: Helm
            app.kubernetes.io/name: prometheus-node-exporter
            app.kubernetes.io/part-of: prometheus-node-exporter
            app.kubernetes.io/version: 1.10.2
            helm.sh/chart: prometheus-node-exporter-4.49.1
            jobLabel: node-exporter
            release: monitoring
        spec:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: eks.amazonaws.com/compute-type
                        operator: NotIn
                        values:
                          - fargate
                      - key: type
                        operator: NotIn
                        values:
                          - virtual-kubelet
          automountServiceAccountToken: false
          containers:
            - args:
                - --path.procfs=/host/proc
                - --path.sysfs=/host/sys
                - --path.rootfs=/host/root
                - --path.udev.data=/host/root/run/udev/data
                - --web.listen-address=[$(HOST_IP)]:9100
                - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/containerd/.+|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
                - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs|erofs)$
              env:
                - name: HOST_IP
                  value: 0.0.0.0
              image: quay.io/prometheus/node-exporter:v1.10.2
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 3
                httpGet:
                  path: /
                  port: http-metrics
                  scheme: HTTP
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              name: node-exporter
              ports:
                - containerPort: 9100
                  name: http-metrics
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /
                  port: http-metrics
                  scheme: HTTP
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              resources: {}
              securityContext:
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /host/proc
                  name: proc
                  readOnly: true
                - mountPath: /host/sys
                  name: sys
                  readOnly: true
                - mountPath: /host/root
                  mountPropagation: HostToContainer
                  name: root
                  readOnly: true
          dnsPolicy: ClusterFirst
          hostNetwork: true
          hostPID: true
          nodeSelector:
            kubernetes.io/os: linux
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 65534
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
          serviceAccount: monitoring-prometheus-node-exporter
          serviceAccountName: monitoring-prometheus-node-exporter
          terminationGracePeriodSeconds: 30
          tolerations:
            - effect: NoSchedule
              operator: Exists
          volumes:
            - hostPath:
                path: /proc
                type: ""
              name: proc
            - hostPath:
                path: /sys
                type: ""
              name: sys
            - hostPath:
                path: /
                type: ""
              name: root
      updateStrategy:
        rollingUpdate:
          maxSurge: 0
          maxUnavailable: 1
        type: RollingUpdate
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      annotations:
        deployment.kubernetes.io/revision: "2"
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: grafana
        app.kubernetes.io/version: 12.3.0
        helm.sh/chart: grafana-10.1.5
      name: monitoring-grafana
      namespace: monitoring
    spec:
      progressDeadlineSeconds: 600
      replicas: 1
      revisionHistoryLimit: 10
      selector:
        matchLabels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
      strategy:
        rollingUpdate:
          maxSurge: 25%
          maxUnavailable: 25%
        type: RollingUpdate
      template:
        metadata:
          annotations:
            checksum/config: b19ad569963f94db78b150b97c208a759fb48b7234cd8be344c5218229c5c6c8
            checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
            checksum/secret: 7f0cdf9c1d7c2511f85367d925e7b20f3e81cbfaabc23fd10f289b0f52eedd76
            kubectl.kubernetes.io/default-container: grafana
          creationTimestamp: null
          labels:
            app.kubernetes.io/instance: monitoring
            app.kubernetes.io/name: grafana
            app.kubernetes.io/version: 12.3.0
            helm.sh/chart: grafana-10.1.5
        spec:
          automountServiceAccountToken: true
          containers:
            - env:
                - name: METHOD
                  value: WATCH
                - name: LABEL
                  value: grafana_dashboard
                - name: LABEL_VALUE
                  value: "1"
                - name: FOLDER
                  value: /tmp/dashboards
                - name: RESOURCE
                  value: both
                - name: NAMESPACE
                  value: ALL
                - name: REQ_USERNAME
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: REQ_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: REQ_URL
                  value: http://localhost:3000/api/admin/provisioning/dashboards/reload
                - name: REQ_METHOD
                  value: POST
              image: quay.io/kiwigrid/k8s-sidecar:1.30.10
              imagePullPolicy: IfNotPresent
              name: grafana-sc-dashboard
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /tmp/dashboards
                  name: sc-dashboard-volume
            - env:
                - name: METHOD
                  value: WATCH
                - name: LABEL
                  value: grafana_datasource
                - name: LABEL_VALUE
                  value: "1"
                - name: FOLDER
                  value: /etc/grafana/provisioning/datasources
                - name: RESOURCE
                  value: both
                - name: REQ_USERNAME
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: REQ_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: REQ_URL
                  value: http://localhost:3000/api/admin/provisioning/datasources/reload
                - name: REQ_METHOD
                  value: POST
              image: quay.io/kiwigrid/k8s-sidecar:1.30.10
              imagePullPolicy: IfNotPresent
              name: grafana-sc-datasources
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /etc/grafana/provisioning/datasources
                  name: sc-datasources-volume
            - env:
                - name: POD_IP
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: status.podIP
                - name: GF_SECURITY_ADMIN_USER
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: GF_SECURITY_ADMIN_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: GF_PATHS_DATA
                  value: /var/lib/grafana/
                - name: GF_PATHS_LOGS
                  value: /var/log/grafana
                - name: GF_PATHS_PLUGINS
                  value: /var/lib/grafana/plugins
                - name: GF_PATHS_PROVISIONING
                  value: /etc/grafana/provisioning
              image: docker.io/grafana/grafana:12.3.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 10
                httpGet:
                  path: /api/health
                  port: 3000
                  scheme: HTTP
                initialDelaySeconds: 60
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 30
              name: grafana
              ports:
                - containerPort: 3000
                  name: grafana
                  protocol: TCP
                - containerPort: 9094
                  name: gossip-tcp
                  protocol: TCP
                - containerPort: 9094
                  name: gossip-udp
                  protocol: UDP
                - containerPort: 6060
                  name: profiling
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /api/health
                  port: 3000
                  scheme: HTTP
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /etc/grafana/grafana.ini
                  name: config
                  subPath: grafana.ini
                - mountPath: /var/lib/grafana
                  name: storage
                - mountPath: /tmp/dashboards
                  name: sc-dashboard-volume
                - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
                  name: sc-dashboard-provider
                  subPath: provider.yaml
                - mountPath: /etc/grafana/provisioning/datasources
                  name: sc-datasources-volume
          dnsPolicy: ClusterFirst
          enableServiceLinks: true
          initContainers:
            - command:
                - chown
                - -R
                - 472:472
                - /var/lib/grafana
              image: docker.io/library/busybox:1.31.1
              imagePullPolicy: IfNotPresent
              name: init-chown-data
              resources: {}
              securityContext:
                capabilities:
                  add:
                    - CHOWN
                  drop:
                    - ALL
                readOnlyRootFilesystem: false
                runAsNonRoot: false
                runAsUser: 0
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /var/lib/grafana
                  name: storage
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 472
            runAsGroup: 472
            runAsNonRoot: true
            runAsUser: 472
          serviceAccount: monitoring-grafana
          serviceAccountName: monitoring-grafana
          shareProcessNamespace: false
          terminationGracePeriodSeconds: 30
          volumes:
            - configMap:
                defaultMode: 420
                name: monitoring-grafana
              name: config
            - name: storage
              persistentVolumeClaim:
                claimName: monitoring-grafana
            - emptyDir: {}
              name: sc-dashboard-volume
            - configMap:
                defaultMode: 420
                name: monitoring-grafana-config-dashboards
              name: sc-dashboard-provider
            - emptyDir: {}
              name: sc-datasources-volume
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      annotations:
        deployment.kubernetes.io/revision: "1"
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app: kube-prometheus-stack-operator
        app.kubernetes.io/component: prometheus-operator
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
        app.kubernetes.io/part-of: kube-prometheus-stack
        app.kubernetes.io/version: 79.6.1
        chart: kube-prometheus-stack-79.6.1
        heritage: Helm
        release: monitoring
      name: monitoring-kube-prometheus-operator
      namespace: monitoring
    spec:
      progressDeadlineSeconds: 600
      replicas: 1
      revisionHistoryLimit: 10
      selector:
        matchLabels:
          app: kube-prometheus-stack-operator
          release: monitoring
      strategy:
        rollingUpdate:
          maxSurge: 25%
          maxUnavailable: 25%
        type: RollingUpdate
      template:
        metadata:
          creationTimestamp: null
          labels:
            app: kube-prometheus-stack-operator
            app.kubernetes.io/component: prometheus-operator
            app.kubernetes.io/instance: monitoring
            app.kubernetes.io/managed-by: Helm
            app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
            app.kubernetes.io/part-of: kube-prometheus-stack
            app.kubernetes.io/version: 79.6.1
            chart: kube-prometheus-stack-79.6.1
            heritage: Helm
            release: monitoring
        spec:
          automountServiceAccountToken: true
          containers:
            - args:
                - --kubelet-service=kube-system/monitoring-kube-prometheus-kubelet
                - --kubelet-endpoints=true
                - --kubelet-endpointslice=false
                - --localhost=127.0.0.1
                - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
                - --config-reloader-cpu-request=0
                - --config-reloader-cpu-limit=0
                - --config-reloader-memory-request=0
                - --config-reloader-memory-limit=0
                - --thanos-default-base-image=quay.io/thanos/thanos:v0.40.1
                - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
                - --web.enable-tls=true
                - --web.cert-file=/cert/cert
                - --web.key-file=/cert/key
                - --web.listen-address=:10250
                - --web.tls-min-version=VersionTLS13
              env:
                - name: GOGC
                  value: "30"
              image: quay.io/prometheus-operator/prometheus-operator:v0.86.2
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 3
                httpGet:
                  path: /healthz
                  port: https
                  scheme: HTTPS
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              name: kube-prometheus-stack
              ports:
                - containerPort: 10250
                  name: https
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /healthz
                  port: https
                  scheme: HTTPS
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /cert
                  name: tls-secret
                  readOnly: true
          dnsPolicy: ClusterFirst
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 65534
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          serviceAccount: monitoring-kube-prometheus-operator
          serviceAccountName: monitoring-kube-prometheus-operator
          terminationGracePeriodSeconds: 30
          volumes:
            - name: tls-secret
              secret:
                defaultMode: 420
                secretName: monitoring-kube-prometheus-admission
  - apiVersion: apps/v1
    kind: Deployment
    metadata:
      annotations:
        deployment.kubernetes.io/revision: "1"
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/part-of: kube-state-metrics
        app.kubernetes.io/version: 2.17.0
        helm.sh/chart: kube-state-metrics-6.4.1
        release: monitoring
      name: monitoring-kube-state-metrics
      namespace: monitoring
    spec:
      progressDeadlineSeconds: 600
      replicas: 1
      revisionHistoryLimit: 10
      selector:
        matchLabels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: kube-state-metrics
      strategy:
        rollingUpdate:
          maxSurge: 25%
          maxUnavailable: 25%
        type: RollingUpdate
      template:
        metadata:
          creationTimestamp: null
          labels:
            app.kubernetes.io/component: metrics
            app.kubernetes.io/instance: monitoring
            app.kubernetes.io/managed-by: Helm
            app.kubernetes.io/name: kube-state-metrics
            app.kubernetes.io/part-of: kube-state-metrics
            app.kubernetes.io/version: 2.17.0
            helm.sh/chart: kube-state-metrics-6.4.1
            release: monitoring
        spec:
          automountServiceAccountToken: true
          containers:
            - args:
                - --port=8080
                - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
              image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 3
                httpGet:
                  path: /livez
                  port: 8080
                  scheme: HTTP
                initialDelaySeconds: 5
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 5
              name: kube-state-metrics
              ports:
                - containerPort: 8080
                  name: http
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /readyz
                  port: 8081
                  scheme: HTTP
                initialDelaySeconds: 5
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 5
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
          dnsPolicy: ClusterFirst
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 65534
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          serviceAccount: monitoring-kube-state-metrics
          serviceAccountName: monitoring-kube-state-metrics
          terminationGracePeriodSeconds: 30
  - apiVersion: apps/v1
    kind: ReplicaSet
    metadata:
      annotations:
        deployment.kubernetes.io/desired-replicas: "1"
        deployment.kubernetes.io/max-replicas: "2"
        deployment.kubernetes.io/revision: "2"
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
        app.kubernetes.io/version: 12.3.0
        helm.sh/chart: grafana-10.1.5
        pod-template-hash: 7466f5b78c
      name: monitoring-grafana-7466f5b78c
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: Deployment
          name: monitoring-grafana
          uid: df0449f6-f5eb-4a4f-94e3-fb1534e89249
    spec:
      replicas: 1
      selector:
        matchLabels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
          pod-template-hash: 7466f5b78c
      template:
        metadata:
          annotations:
            checksum/config: b19ad569963f94db78b150b97c208a759fb48b7234cd8be344c5218229c5c6c8
            checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
            checksum/secret: 7f0cdf9c1d7c2511f85367d925e7b20f3e81cbfaabc23fd10f289b0f52eedd76
            kubectl.kubernetes.io/default-container: grafana
          creationTimestamp: null
          labels:
            app.kubernetes.io/instance: monitoring
            app.kubernetes.io/name: grafana
            app.kubernetes.io/version: 12.3.0
            helm.sh/chart: grafana-10.1.5
            pod-template-hash: 7466f5b78c
        spec:
          automountServiceAccountToken: true
          containers:
            - env:
                - name: METHOD
                  value: WATCH
                - name: LABEL
                  value: grafana_dashboard
                - name: LABEL_VALUE
                  value: "1"
                - name: FOLDER
                  value: /tmp/dashboards
                - name: RESOURCE
                  value: both
                - name: NAMESPACE
                  value: ALL
                - name: REQ_USERNAME
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: REQ_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: REQ_URL
                  value: http://localhost:3000/api/admin/provisioning/dashboards/reload
                - name: REQ_METHOD
                  value: POST
              image: quay.io/kiwigrid/k8s-sidecar:1.30.10
              imagePullPolicy: IfNotPresent
              name: grafana-sc-dashboard
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /tmp/dashboards
                  name: sc-dashboard-volume
            - env:
                - name: METHOD
                  value: WATCH
                - name: LABEL
                  value: grafana_datasource
                - name: LABEL_VALUE
                  value: "1"
                - name: FOLDER
                  value: /etc/grafana/provisioning/datasources
                - name: RESOURCE
                  value: both
                - name: REQ_USERNAME
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: REQ_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: REQ_URL
                  value: http://localhost:3000/api/admin/provisioning/datasources/reload
                - name: REQ_METHOD
                  value: POST
              image: quay.io/kiwigrid/k8s-sidecar:1.30.10
              imagePullPolicy: IfNotPresent
              name: grafana-sc-datasources
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /etc/grafana/provisioning/datasources
                  name: sc-datasources-volume
            - env:
                - name: POD_IP
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: status.podIP
                - name: GF_SECURITY_ADMIN_USER
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: GF_SECURITY_ADMIN_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: GF_PATHS_DATA
                  value: /var/lib/grafana/
                - name: GF_PATHS_LOGS
                  value: /var/log/grafana
                - name: GF_PATHS_PLUGINS
                  value: /var/lib/grafana/plugins
                - name: GF_PATHS_PROVISIONING
                  value: /etc/grafana/provisioning
              image: docker.io/grafana/grafana:12.3.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 10
                httpGet:
                  path: /api/health
                  port: 3000
                  scheme: HTTP
                initialDelaySeconds: 60
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 30
              name: grafana
              ports:
                - containerPort: 3000
                  name: grafana
                  protocol: TCP
                - containerPort: 9094
                  name: gossip-tcp
                  protocol: TCP
                - containerPort: 9094
                  name: gossip-udp
                  protocol: UDP
                - containerPort: 6060
                  name: profiling
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /api/health
                  port: 3000
                  scheme: HTTP
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /etc/grafana/grafana.ini
                  name: config
                  subPath: grafana.ini
                - mountPath: /var/lib/grafana
                  name: storage
                - mountPath: /tmp/dashboards
                  name: sc-dashboard-volume
                - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
                  name: sc-dashboard-provider
                  subPath: provider.yaml
                - mountPath: /etc/grafana/provisioning/datasources
                  name: sc-datasources-volume
          dnsPolicy: ClusterFirst
          enableServiceLinks: true
          initContainers:
            - command:
                - chown
                - -R
                - 472:472
                - /var/lib/grafana
              image: docker.io/library/busybox:1.31.1
              imagePullPolicy: IfNotPresent
              name: init-chown-data
              resources: {}
              securityContext:
                capabilities:
                  add:
                    - CHOWN
                  drop:
                    - ALL
                readOnlyRootFilesystem: false
                runAsNonRoot: false
                runAsUser: 0
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /var/lib/grafana
                  name: storage
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 472
            runAsGroup: 472
            runAsNonRoot: true
            runAsUser: 472
          serviceAccount: monitoring-grafana
          serviceAccountName: monitoring-grafana
          shareProcessNamespace: false
          terminationGracePeriodSeconds: 30
          volumes:
            - configMap:
                defaultMode: 420
                name: monitoring-grafana
              name: config
            - name: storage
              persistentVolumeClaim:
                claimName: monitoring-grafana
            - emptyDir: {}
              name: sc-dashboard-volume
            - configMap:
                defaultMode: 420
                name: monitoring-grafana-config-dashboards
              name: sc-dashboard-provider
            - emptyDir: {}
              name: sc-datasources-volume
  - apiVersion: apps/v1
    kind: ReplicaSet
    metadata:
      annotations:
        deployment.kubernetes.io/desired-replicas: "1"
        deployment.kubernetes.io/max-replicas: "2"
        deployment.kubernetes.io/revision: "1"
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
        app.kubernetes.io/version: 12.3.0
        helm.sh/chart: grafana-10.1.5
        pod-template-hash: 8468fcc794
      name: monitoring-grafana-8468fcc794
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: Deployment
          name: monitoring-grafana
          uid: df0449f6-f5eb-4a4f-94e3-fb1534e89249
    spec:
      replicas: 0
      selector:
        matchLabels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
          pod-template-hash: 8468fcc794
      template:
        metadata:
          annotations:
            checksum/config: b19ad569963f94db78b150b97c208a759fb48b7234cd8be344c5218229c5c6c8
            checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
            checksum/secret: 19cf65593462ae9426f429010bf4f3fe500be6b8937b6c13112cad2b27e6a24a
            kubectl.kubernetes.io/default-container: grafana
          creationTimestamp: null
          labels:
            app.kubernetes.io/instance: monitoring
            app.kubernetes.io/name: grafana
            app.kubernetes.io/version: 12.3.0
            helm.sh/chart: grafana-10.1.5
            pod-template-hash: 8468fcc794
        spec:
          automountServiceAccountToken: true
          containers:
            - env:
                - name: METHOD
                  value: WATCH
                - name: LABEL
                  value: grafana_dashboard
                - name: LABEL_VALUE
                  value: "1"
                - name: FOLDER
                  value: /tmp/dashboards
                - name: RESOURCE
                  value: both
                - name: NAMESPACE
                  value: ALL
                - name: REQ_USERNAME
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: REQ_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: REQ_URL
                  value: http://localhost:3000/api/admin/provisioning/dashboards/reload
                - name: REQ_METHOD
                  value: POST
              image: quay.io/kiwigrid/k8s-sidecar:1.30.10
              imagePullPolicy: IfNotPresent
              name: grafana-sc-dashboard
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /tmp/dashboards
                  name: sc-dashboard-volume
            - env:
                - name: METHOD
                  value: WATCH
                - name: LABEL
                  value: grafana_datasource
                - name: LABEL_VALUE
                  value: "1"
                - name: FOLDER
                  value: /etc/grafana/provisioning/datasources
                - name: RESOURCE
                  value: both
                - name: REQ_USERNAME
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: REQ_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: REQ_URL
                  value: http://localhost:3000/api/admin/provisioning/datasources/reload
                - name: REQ_METHOD
                  value: POST
              image: quay.io/kiwigrid/k8s-sidecar:1.30.10
              imagePullPolicy: IfNotPresent
              name: grafana-sc-datasources
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /etc/grafana/provisioning/datasources
                  name: sc-datasources-volume
            - env:
                - name: POD_IP
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: status.podIP
                - name: GF_SECURITY_ADMIN_USER
                  valueFrom:
                    secretKeyRef:
                      key: admin-user
                      name: monitoring-grafana
                - name: GF_SECURITY_ADMIN_PASSWORD
                  valueFrom:
                    secretKeyRef:
                      key: admin-password
                      name: monitoring-grafana
                - name: GF_PATHS_DATA
                  value: /var/lib/grafana/
                - name: GF_PATHS_LOGS
                  value: /var/log/grafana
                - name: GF_PATHS_PLUGINS
                  value: /var/lib/grafana/plugins
                - name: GF_PATHS_PROVISIONING
                  value: /etc/grafana/provisioning
              image: docker.io/grafana/grafana:12.3.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 10
                httpGet:
                  path: /api/health
                  port: 3000
                  scheme: HTTP
                initialDelaySeconds: 60
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 30
              name: grafana
              ports:
                - containerPort: 3000
                  name: grafana
                  protocol: TCP
                - containerPort: 9094
                  name: gossip-tcp
                  protocol: TCP
                - containerPort: 9094
                  name: gossip-udp
                  protocol: UDP
                - containerPort: 6060
                  name: profiling
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /api/health
                  port: 3000
                  scheme: HTTP
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /etc/grafana/grafana.ini
                  name: config
                  subPath: grafana.ini
                - mountPath: /var/lib/grafana
                  name: storage
                - mountPath: /tmp/dashboards
                  name: sc-dashboard-volume
                - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
                  name: sc-dashboard-provider
                  subPath: provider.yaml
                - mountPath: /etc/grafana/provisioning/datasources
                  name: sc-datasources-volume
          dnsPolicy: ClusterFirst
          enableServiceLinks: true
          initContainers:
            - command:
                - chown
                - -R
                - 472:472
                - /var/lib/grafana
              image: docker.io/library/busybox:1.31.1
              imagePullPolicy: IfNotPresent
              name: init-chown-data
              resources: {}
              securityContext:
                capabilities:
                  add:
                    - CHOWN
                  drop:
                    - ALL
                readOnlyRootFilesystem: false
                runAsNonRoot: false
                runAsUser: 0
                seccompProfile:
                  type: RuntimeDefault
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /var/lib/grafana
                  name: storage
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 472
            runAsGroup: 472
            runAsNonRoot: true
            runAsUser: 472
          serviceAccount: monitoring-grafana
          serviceAccountName: monitoring-grafana
          shareProcessNamespace: false
          terminationGracePeriodSeconds: 30
          volumes:
            - configMap:
                defaultMode: 420
                name: monitoring-grafana
              name: config
            - name: storage
              persistentVolumeClaim:
                claimName: monitoring-grafana
            - emptyDir: {}
              name: sc-dashboard-volume
            - configMap:
                defaultMode: 420
                name: monitoring-grafana-config-dashboards
              name: sc-dashboard-provider
            - emptyDir: {}
              name: sc-datasources-volume
  - apiVersion: apps/v1
    kind: ReplicaSet
    metadata:
      annotations:
        deployment.kubernetes.io/desired-replicas: "1"
        deployment.kubernetes.io/max-replicas: "2"
        deployment.kubernetes.io/revision: "1"
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app: kube-prometheus-stack-operator
        app.kubernetes.io/component: prometheus-operator
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
        app.kubernetes.io/part-of: kube-prometheus-stack
        app.kubernetes.io/version: 79.6.1
        chart: kube-prometheus-stack-79.6.1
        heritage: Helm
        pod-template-hash: 568b8d6b68
        release: monitoring
      name: monitoring-kube-prometheus-operator-568b8d6b68
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: Deployment
          name: monitoring-kube-prometheus-operator
          uid: dbcff942-a729-433b-a4a5-a02eddca10eb
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: kube-prometheus-stack-operator
          pod-template-hash: 568b8d6b68
          release: monitoring
      template:
        metadata:
          creationTimestamp: null
          labels:
            app: kube-prometheus-stack-operator
            app.kubernetes.io/component: prometheus-operator
            app.kubernetes.io/instance: monitoring
            app.kubernetes.io/managed-by: Helm
            app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
            app.kubernetes.io/part-of: kube-prometheus-stack
            app.kubernetes.io/version: 79.6.1
            chart: kube-prometheus-stack-79.6.1
            heritage: Helm
            pod-template-hash: 568b8d6b68
            release: monitoring
        spec:
          automountServiceAccountToken: true
          containers:
            - args:
                - --kubelet-service=kube-system/monitoring-kube-prometheus-kubelet
                - --kubelet-endpoints=true
                - --kubelet-endpointslice=false
                - --localhost=127.0.0.1
                - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
                - --config-reloader-cpu-request=0
                - --config-reloader-cpu-limit=0
                - --config-reloader-memory-request=0
                - --config-reloader-memory-limit=0
                - --thanos-default-base-image=quay.io/thanos/thanos:v0.40.1
                - --secret-field-selector=type!=kubernetes.io/dockercfg,type!=kubernetes.io/service-account-token,type!=helm.sh/release.v1
                - --web.enable-tls=true
                - --web.cert-file=/cert/cert
                - --web.key-file=/cert/key
                - --web.listen-address=:10250
                - --web.tls-min-version=VersionTLS13
              env:
                - name: GOGC
                  value: "30"
              image: quay.io/prometheus-operator/prometheus-operator:v0.86.2
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 3
                httpGet:
                  path: /healthz
                  port: https
                  scheme: HTTPS
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              name: kube-prometheus-stack
              ports:
                - containerPort: 10250
                  name: https
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /healthz
                  port: https
                  scheme: HTTPS
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 1
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
              volumeMounts:
                - mountPath: /cert
                  name: tls-secret
                  readOnly: true
          dnsPolicy: ClusterFirst
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 65534
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          serviceAccount: monitoring-kube-prometheus-operator
          serviceAccountName: monitoring-kube-prometheus-operator
          terminationGracePeriodSeconds: 30
          volumes:
            - name: tls-secret
              secret:
                defaultMode: 420
                secretName: monitoring-kube-prometheus-admission
  - apiVersion: apps/v1
    kind: ReplicaSet
    metadata:
      annotations:
        deployment.kubernetes.io/desired-replicas: "1"
        deployment.kubernetes.io/max-replicas: "2"
        deployment.kubernetes.io/revision: "1"
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
      labels:
        app.kubernetes.io/component: metrics
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/part-of: kube-state-metrics
        app.kubernetes.io/version: 2.17.0
        helm.sh/chart: kube-state-metrics-6.4.1
        pod-template-hash: 7984768b56
        release: monitoring
      name: monitoring-kube-state-metrics-7984768b56
      namespace: monitoring
      ownerReferences:
        - apiVersion: apps/v1
          blockOwnerDeletion: true
          controller: true
          kind: Deployment
          name: monitoring-kube-state-metrics
          uid: 88660350-3274-42d5-988d-cd2b6a199338
    spec:
      replicas: 1
      selector:
        matchLabels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: kube-state-metrics
          pod-template-hash: 7984768b56
      template:
        metadata:
          creationTimestamp: null
          labels:
            app.kubernetes.io/component: metrics
            app.kubernetes.io/instance: monitoring
            app.kubernetes.io/managed-by: Helm
            app.kubernetes.io/name: kube-state-metrics
            app.kubernetes.io/part-of: kube-state-metrics
            app.kubernetes.io/version: 2.17.0
            helm.sh/chart: kube-state-metrics-6.4.1
            pod-template-hash: 7984768b56
            release: monitoring
        spec:
          automountServiceAccountToken: true
          containers:
            - args:
                - --port=8080
                - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
              image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 3
                httpGet:
                  path: /livez
                  port: 8080
                  scheme: HTTP
                initialDelaySeconds: 5
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 5
              name: kube-state-metrics
              ports:
                - containerPort: 8080
                  name: http
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /readyz
                  port: 8081
                  scheme: HTTP
                initialDelaySeconds: 5
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 5
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
          dnsPolicy: ClusterFirst
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 65534
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
            seccompProfile:
              type: RuntimeDefault
          serviceAccount: monitoring-kube-state-metrics
          serviceAccountName: monitoring-kube-state-metrics
          terminationGracePeriodSeconds: 30
  - apiVersion: apps/v1
    kind: StatefulSet
    metadata:
      annotations:
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
        prometheus-operator-input-hash: "7333261605762747118"
      labels:
        alertmanager: monitoring-kube-prometheus-alertmanager
        app: kube-prometheus-stack-alertmanager
        app.kubernetes.io/instance: monitoring-kube-prometheus-alertmanager
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: alertmanager
        app.kubernetes.io/part-of: kube-prometheus-stack
        app.kubernetes.io/version: 79.6.1
        chart: kube-prometheus-stack-79.6.1
        heritage: Helm
        managed-by: prometheus-operator
        release: monitoring
      name: alertmanager-monitoring-kube-prometheus-alertmanager
      namespace: monitoring
      ownerReferences:
        - apiVersion: monitoring.coreos.com/v1
          blockOwnerDeletion: true
          controller: true
          kind: Alertmanager
          name: monitoring-kube-prometheus-alertmanager
          uid: 56e0a879-e38a-4b61-88ef-52a0181a7209
    spec:
      persistentVolumeClaimRetentionPolicy:
        whenDeleted: Retain
        whenScaled: Retain
      podManagementPolicy: Parallel
      replicas: 1
      revisionHistoryLimit: 10
      selector:
        matchLabels:
          alertmanager: monitoring-kube-prometheus-alertmanager
          app.kubernetes.io/instance: monitoring-kube-prometheus-alertmanager
          app.kubernetes.io/managed-by: prometheus-operator
          app.kubernetes.io/name: alertmanager
      serviceName: alertmanager-operated
      template:
        metadata:
          annotations:
            kubectl.kubernetes.io/default-container: alertmanager
          creationTimestamp: null
          labels:
            alertmanager: monitoring-kube-prometheus-alertmanager
            app.kubernetes.io/instance: monitoring-kube-prometheus-alertmanager
            app.kubernetes.io/managed-by: prometheus-operator
            app.kubernetes.io/name: alertmanager
            app.kubernetes.io/version: 0.29.0
        spec:
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
                - podAffinityTerm:
                    labelSelector:
                      matchExpressions:
                        - key: app.kubernetes.io/name
                          operator: In
                          values:
                            - alertmanager
                        - key: alertmanager
                          operator: In
                          values:
                            - monitoring-kube-prometheus-alertmanager
                    topologyKey: kubernetes.io/hostname
                  weight: 100
          automountServiceAccountToken: true
          containers:
            - args:
                - --config.file=/etc/alertmanager/config_out/alertmanager.env.yaml
                - --storage.path=/alertmanager
                - --data.retention=120h
                - --cluster.listen-address=
                - --web.listen-address=:9093
                - --web.external-url=http://monitoring-kube-prometheus-alertmanager.monitoring:9093
                - --web.route-prefix=/
                - --cluster.label=monitoring/monitoring-kube-prometheus-alertmanager
                - --cluster.peer=alertmanager-monitoring-kube-prometheus-alertmanager-0.alertmanager-operated:9094
                - --cluster.reconnect-timeout=5m
                - --web.config.file=/etc/alertmanager/web_config/web-config.yaml
              env:
                - name: POD_IP
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: status.podIP
              image: quay.io/prometheus/alertmanager:v0.29.0
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 10
                httpGet:
                  path: /-/healthy
                  port: http-web
                  scheme: HTTP
                periodSeconds: 10
                successThreshold: 1
                timeoutSeconds: 3
              name: alertmanager
              ports:
                - containerPort: 9093
                  name: http-web
                  protocol: TCP
                - containerPort: 9094
                  name: mesh-tcp
                  protocol: TCP
                - containerPort: 9094
                  name: mesh-udp
                  protocol: UDP
              readinessProbe:
                failureThreshold: 10
                httpGet:
                  path: /-/ready
                  port: http-web
                  scheme: HTTP
                initialDelaySeconds: 3
                periodSeconds: 5
                successThreshold: 1
                timeoutSeconds: 3
              resources:
                requests:
                  memory: 200Mi
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: FallbackToLogsOnError
              volumeMounts:
                - mountPath: /etc/alertmanager/config
                  name: config-volume
                - mountPath: /etc/alertmanager/config_out
                  name: config-out
                  readOnly: true
                - mountPath: /etc/alertmanager/certs
                  name: tls-assets
                  readOnly: true
                - mountPath: /alertmanager
                  name: alertmanager-monitoring-kube-prometheus-alertmanager-db
                - mountPath: /etc/alertmanager/web_config/web-config.yaml
                  name: web-config
                  readOnly: true
                  subPath: web-config.yaml
                - mountPath: /etc/alertmanager/cluster_tls_config/cluster-tls-config.yaml
                  name: cluster-tls-config
                  readOnly: true
                  subPath: cluster-tls-config.yaml
            - args:
                - --listen-address=:8080
                - --web-config-file=/etc/alertmanager/web_config/web-config.yaml
                - --reload-url=http://127.0.0.1:9093/-/reload
                - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
                - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
                - --watched-dir=/etc/alertmanager/config
              command:
                - /bin/prometheus-config-reloader
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: metadata.name
                - name: SHARD
                  value: "-1"
              image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
              imagePullPolicy: IfNotPresent
              name: config-reloader
              ports:
                - containerPort: 8080
                  name: reloader-web
                  protocol: TCP
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: FallbackToLogsOnError
              volumeMounts:
                - mountPath: /etc/alertmanager/config
                  name: config-volume
                  readOnly: true
                - mountPath: /etc/alertmanager/config_out
                  name: config-out
                - mountPath: /etc/alertmanager/web_config/web-config.yaml
                  name: web-config
                  readOnly: true
                  subPath: web-config.yaml
          dnsPolicy: ClusterFirst
          initContainers:
            - args:
                - --watch-interval=0
                - --listen-address=:8081
                - --config-file=/etc/alertmanager/config/alertmanager.yaml.gz
                - --config-envsubst-file=/etc/alertmanager/config_out/alertmanager.env.yaml
                - --watched-dir=/etc/alertmanager/config
              command:
                - /bin/prometheus-config-reloader
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: metadata.name
                - name: SHARD
                  value: "-1"
              image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
              imagePullPolicy: IfNotPresent
              name: init-config-reloader
              ports:
                - containerPort: 8081
                  name: reloader-init
                  protocol: TCP
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: FallbackToLogsOnError
              volumeMounts:
                - mountPath: /etc/alertmanager/config
                  name: config-volume
                  readOnly: true
                - mountPath: /etc/alertmanager/config_out
                  name: config-out
                - mountPath: /etc/alertmanager/web_config/web-config.yaml
                  name: web-config
                  readOnly: true
                  subPath: web-config.yaml
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 2000
            runAsGroup: 2000
            runAsNonRoot: true
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
          serviceAccount: monitoring-kube-prometheus-alertmanager
          serviceAccountName: monitoring-kube-prometheus-alertmanager
          terminationGracePeriodSeconds: 120
          volumes:
            - name: config-volume
              secret:
                defaultMode: 420
                secretName: alertmanager-monitoring-kube-prometheus-alertmanager-generated
            - name: tls-assets
              projected:
                defaultMode: 420
                sources:
                  - secret:
                      name: alertmanager-monitoring-kube-prometheus-alertmanager-tls-assets-0
            - emptyDir:
                medium: Memory
              name: config-out
            - name: web-config
              secret:
                defaultMode: 420
                secretName: alertmanager-monitoring-kube-prometheus-alertmanager-web-config
            - name: cluster-tls-config
              secret:
                defaultMode: 420
                secretName: alertmanager-monitoring-kube-prometheus-alertmanager-cluster-tls-config
            - emptyDir: {}
              name: alertmanager-monitoring-kube-prometheus-alertmanager-db
      updateStrategy:
        type: RollingUpdate
  - apiVersion: apps/v1
    kind: StatefulSet
    metadata:
      annotations:
        meta.helm.sh/release-name: monitoring
        meta.helm.sh/release-namespace: monitoring
        prometheus-operator-input-hash: "7482013664946716801"
      labels:
        app: kube-prometheus-stack-prometheus
        app.kubernetes.io/instance: monitoring-kube-prometheus-prometheus
        app.kubernetes.io/managed-by: prometheus-operator
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/part-of: kube-prometheus-stack
        app.kubernetes.io/version: 79.6.1
        chart: kube-prometheus-stack-79.6.1
        heritage: Helm
        managed-by: prometheus-operator
        operator.prometheus.io/mode: server
        operator.prometheus.io/name: monitoring-kube-prometheus-prometheus
        operator.prometheus.io/shard: "0"
        prometheus: monitoring-kube-prometheus-prometheus
        release: monitoring
      name: prometheus-monitoring-kube-prometheus-prometheus
      namespace: monitoring
      ownerReferences:
        - apiVersion: monitoring.coreos.com/v1
          blockOwnerDeletion: true
          controller: true
          kind: Prometheus
          name: monitoring-kube-prometheus-prometheus
          uid: d52be81e-22a1-483b-861a-2ca76ba85f38
    spec:
      persistentVolumeClaimRetentionPolicy:
        whenDeleted: Retain
        whenScaled: Retain
      podManagementPolicy: Parallel
      replicas: 1
      revisionHistoryLimit: 10
      selector:
        matchLabels:
          app.kubernetes.io/instance: monitoring-kube-prometheus-prometheus
          app.kubernetes.io/managed-by: prometheus-operator
          app.kubernetes.io/name: prometheus
          operator.prometheus.io/name: monitoring-kube-prometheus-prometheus
          operator.prometheus.io/shard: "0"
          prometheus: monitoring-kube-prometheus-prometheus
      serviceName: prometheus-operated
      template:
        metadata:
          annotations:
            kubectl.kubernetes.io/default-container: prometheus
          creationTimestamp: null
          labels:
            app.kubernetes.io/instance: monitoring-kube-prometheus-prometheus
            app.kubernetes.io/managed-by: prometheus-operator
            app.kubernetes.io/name: prometheus
            app.kubernetes.io/version: 3.7.3
            operator.prometheus.io/name: monitoring-kube-prometheus-prometheus
            operator.prometheus.io/shard: "0"
            prometheus: monitoring-kube-prometheus-prometheus
        spec:
          affinity:
            podAntiAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
                - podAffinityTerm:
                    labelSelector:
                      matchExpressions:
                        - key: app.kubernetes.io/name
                          operator: In
                          values:
                            - prometheus
                        - key: app.kubernetes.io/instance
                          operator: In
                          values:
                            - monitoring-kube-prometheus-prometheus
                    topologyKey: kubernetes.io/hostname
                  weight: 100
          automountServiceAccountToken: true
          containers:
            - args:
                - --config.file=/etc/prometheus/config_out/prometheus.env.yaml
                - --web.enable-lifecycle
                - --web.external-url=http://prometheus.kwiki.it.com/
                - --web.route-prefix=/
                - --storage.tsdb.retention.time=10d
                - --storage.tsdb.path=/prometheus
                - --storage.tsdb.wal-compression
                - --web.config.file=/etc/prometheus/web_config/web-config.yaml
              image: quay.io/prometheus/prometheus:v3.7.3
              imagePullPolicy: IfNotPresent
              livenessProbe:
                failureThreshold: 6
                httpGet:
                  path: /-/healthy
                  port: http-web
                  scheme: HTTP
                periodSeconds: 5
                successThreshold: 1
                timeoutSeconds: 3
              name: prometheus
              ports:
                - containerPort: 9090
                  name: http-web
                  protocol: TCP
              readinessProbe:
                failureThreshold: 3
                httpGet:
                  path: /-/ready
                  port: http-web
                  scheme: HTTP
                periodSeconds: 5
                successThreshold: 1
                timeoutSeconds: 3
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              startupProbe:
                failureThreshold: 60
                httpGet:
                  path: /-/ready
                  port: http-web
                  scheme: HTTP
                periodSeconds: 15
                successThreshold: 1
                timeoutSeconds: 3
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: FallbackToLogsOnError
              volumeMounts:
                - mountPath: /etc/prometheus/config_out
                  name: config-out
                  readOnly: true
                - mountPath: /etc/prometheus/certs
                  name: tls-assets
                  readOnly: true
                - mountPath: /prometheus
                  name: prometheus-monitoring-kube-prometheus-prometheus-db
                  subPath: prometheus-db
                - mountPath: /etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
                  name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
                - mountPath: /etc/prometheus/web_config/web-config.yaml
                  name: web-config
                  readOnly: true
                  subPath: web-config.yaml
            - args:
                - --listen-address=:8080
                - --reload-url=http://127.0.0.1:9090/-/reload
                - --config-file=/etc/prometheus/config/prometheus.yaml.gz
                - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
                - --watched-dir=/etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
              command:
                - /bin/prometheus-config-reloader
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: metadata.name
                - name: SHARD
                  value: "0"
              image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
              imagePullPolicy: IfNotPresent
              name: config-reloader
              ports:
                - containerPort: 8080
                  name: reloader-web
                  protocol: TCP
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: FallbackToLogsOnError
              volumeMounts:
                - mountPath: /etc/prometheus/config
                  name: config
                - mountPath: /etc/prometheus/config_out
                  name: config-out
                - mountPath: /etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
                  name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
          dnsPolicy: ClusterFirst
          initContainers:
            - args:
                - --watch-interval=0
                - --listen-address=:8081
                - --config-file=/etc/prometheus/config/prometheus.yaml.gz
                - --config-envsubst-file=/etc/prometheus/config_out/prometheus.env.yaml
                - --watched-dir=/etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
              command:
                - /bin/prometheus-config-reloader
              env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      apiVersion: v1
                      fieldPath: metadata.name
                - name: SHARD
                  value: "0"
              image: quay.io/prometheus-operator/prometheus-config-reloader:v0.86.2
              imagePullPolicy: IfNotPresent
              name: init-config-reloader
              ports:
                - containerPort: 8081
                  name: reloader-init
                  protocol: TCP
              resources: {}
              securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: FallbackToLogsOnError
              volumeMounts:
                - mountPath: /etc/prometheus/config
                  name: config
                - mountPath: /etc/prometheus/config_out
                  name: config-out
                - mountPath: /etc/prometheus/rules/prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
                  name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
          restartPolicy: Always
          schedulerName: default-scheduler
          securityContext:
            fsGroup: 2000
            runAsGroup: 2000
            runAsNonRoot: true
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
          serviceAccount: monitoring-kube-prometheus-prometheus
          serviceAccountName: monitoring-kube-prometheus-prometheus
          shareProcessNamespace: false
          terminationGracePeriodSeconds: 600
          volumes:
            - name: config
              secret:
                defaultMode: 420
                secretName: prometheus-monitoring-kube-prometheus-prometheus
            - name: tls-assets
              projected:
                defaultMode: 420
                sources:
                  - secret:
                      name: prometheus-monitoring-kube-prometheus-prometheus-tls-assets-0
            - emptyDir:
                medium: Memory
              name: config-out
            - configMap:
                defaultMode: 420
                name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
              name: prometheus-monitoring-kube-prometheus-prometheus-rulefiles-0
            - name: web-config
              secret:
                defaultMode: 420
                secretName: prometheus-monitoring-kube-prometheus-prometheus-web-config
      updateStrategy:
        type: RollingUpdate
      volumeClaimTemplates:
        - apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            creationTimestamp: null
            name: prometheus-monitoring-kube-prometheus-prometheus-db
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 20Gi
            storageClassName: longhorn
            volumeMode: Filesystem
          status:
            phase: Pending
kind: List
metadata: {}
